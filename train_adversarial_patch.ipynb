{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_adversarial_patch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFVKSHKU6d4R"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm.notebook import tnrange, tqdm\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.nn as nn\n",
        "\n",
        "from timm import create_model\n",
        "\n",
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
        "print(\"Using device\", device)"
      ],
      "metadata": {
        "id": "ltx8Vh9a7vDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"vit_base_patch16_224\"\n",
        "# create a ViT model : https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n",
        "model = create_model(model_name, pretrained=True).to(device)"
      ],
      "metadata": {
        "id": "iF8Y0tPE92V-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms for test\n",
        "IMG_SIZE = (224, 224)\n",
        "NORMALIZE_MEAN = (0.5, 0.5, 0.5)\n",
        "NORMALIZE_STD = (0.5, 0.5, 0.5)\n",
        "transforms = [\n",
        "              T.Resize(IMG_SIZE),\n",
        "              T.ToTensor(),\n",
        "              T.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "              ]\n",
        "\n",
        "transforms = T.Compose(transforms)"
      ],
      "metadata": {
        "id": "Cx2x4B_D958j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# ImageNet Labels\n",
        "!wget https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt\n",
        "imagenet_labels = dict(enumerate(open('ilsvrc2012_wordnet_lemmas.txt')))\n",
        "short_labels = np.empty([1000], dtype=object)\n",
        "for i in range(len(imagenet_labels.values())):\n",
        "    print(imagenet_labels[i])\n",
        "    left_text = imagenet_labels[i].partition(\",\")[0]\n",
        "    no_newline_label = left_text.partition(\"\\n\")[0]\n",
        "    short_labels[i]=no_newline_label\n",
        "\n",
        "# Demo Image\n",
        "!wget https://github.com/hirotomusiker/schwert_colab_data_storage/blob/master/images/vit_demo/santorini.png?raw=true -O santorini.png\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Senior_Airman_Benton_Pohlman_fires_an_M4_carbine_rifle_%2834135723246%29.jpg/1200px-Senior_Airman_Benton_Pohlman_fires_an_M4_carbine_rifle_%2834135723246%29.jpg -O assault_rifle.jpg\n",
        "img = PIL.Image.open('santorini.png')\n",
        "img_tensor = transforms(img).unsqueeze(0).to(device)\n",
        "\n",
        "\n",
        "# #quick test\n",
        "# output = model(img_tensor)\n",
        "# print(imagenet_labels[int(torch.argmax(output))])"
      ],
      "metadata": {
        "id": "w5C3Hb3U99SG"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR_MEANS, TENSOR_STD = torch.FloatTensor(NORMALIZE_MEAN)[:,None,None], torch.FloatTensor(NORMALIZE_STD)[:,None,None]\n",
        "\n",
        "def patch_forward(patch):\n",
        "    # Map patch values from [-infty,infty] to min and max\n",
        "    patch = (torch.tanh(patch) + 1 - 2 * TENSOR_MEANS) / (2 * TENSOR_STD)\n",
        "    return patch\n",
        "\n",
        "def place_patch(img, patch, coordinates=None):\n",
        "    for i in range(img.shape[0]):\n",
        "        temp = img[i]\n",
        "\n",
        "        if coordinates:\n",
        "            h_offset = coordinates[0]\n",
        "            w_offset = coordinates[1]\n",
        "        else:\n",
        "            h_offset = np.random.randint(0,img.shape[2]-patch.shape[1]-1)\n",
        "            w_offset = np.random.randint(0,img.shape[3]-patch.shape[2]-1)\n",
        "            \n",
        "        temp[:, h_offset:h_offset+patch.shape[1],w_offset:w_offset+patch.shape[2]] = patch_forward(patch)\n",
        "        img[i] = temp\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "Xv8FOhiA99LL"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patch_attack(input_image_path, input_torch_transforms, model, target_class, patch_size, num_epochs, learning_rate, pretrained_patch_path):\n",
        "    \n",
        "    # Create parameter and optimizer\n",
        "    patch_size = (patch_size, patch_size)\n",
        "    if pretrained_patch_path is None:\n",
        "        patch = nn.Parameter(torch.zeros(3, patch_size[0], patch_size[1]), requires_grad=True)\n",
        "    else:\n",
        "        patch_load = torch.load(pretrained_patch_path)\n",
        "        patch = nn.Parameter(torch.tensor(patch_load), requires_grad=True)\n",
        "\n",
        "    optimizer = torch.optim.SGD([patch], lr=learning_rate, momentum=0.8)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[300, 400, 450, 500, 575], gamma=0.4)\n",
        "    loss_module = nn.CrossEntropyLoss()\n",
        "    losses=[]\n",
        "\n",
        "    input_pil_image = Image.open(input_image_path)\n",
        "    input_tensor = input_torch_transforms(input_pil_image)\n",
        "    input_tensor = torch.transpose(input_tensor, 2, 1)\n",
        "\n",
        "    # print(output[0][target_class])\n",
        "\n",
        "    # # Training loop\n",
        "    for epoch in tnrange(num_epochs):\n",
        "\n",
        "        batch =  (input_tensor.unsqueeze(0)).repeat_interleave(8, dim = 0)\n",
        "        patched_batch = place_patch(batch, patch)\n",
        "        pred = model(patched_batch.to(device))\n",
        "        labels = torch.zeros(patched_batch.shape[0], device=pred.device, dtype=torch.long).fill_(target_class)\n",
        "        loss = loss_module(pred, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.mean().backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.mean().cpu().detach().numpy())\n",
        "        plt.plot(losses)\n",
        "        plt.xlabel(\"epochs\")\n",
        "        plt.ylabel(\"loss\")\n",
        "        plt.show()\n",
        "        clear_output(wait=True)\n",
        "\n",
        "    patch_temp=patch.detach().cpu().permute(2, 1, 0)\n",
        "    patch_temp = (torch.tanh(patch_temp) + 1) / 2\n",
        "    patch_temp = np.clip(patch_temp, a_min=0.0, a_max=1.0)\n",
        "    plt.imshow(patch_temp)\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "    print(\"op/ on target class <beta>\", pred[0][target_class])\n",
        "    return(patch)"
      ],
      "metadata": {
        "id": "_Bt4is95wiXy"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
        "final_patch_tensor = patch_attack(input_image_path='assault_rifle.jpg',\n",
        "                                  input_torch_transforms = transforms,\n",
        "                                  model = model, \n",
        "                                  target_class = 605,\n",
        "                                  patch_size = 40,\n",
        "                                  num_epochs = 5,\n",
        "                                  learning_rate=2e-1,\n",
        "                                  pretrained_patch_path= \"patch_class605_size40.pt\")"
      ],
      "metadata": {
        "id": "QlorYE8BJf3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(final_patch_tensor, \"patch_class605_size40.pt\")"
      ],
      "metadata": {
        "id": "b3yk07SwukAa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NormalizeData(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "\n",
        "def attack_image(input_tensor, patch_tensor, coordinates=None):\n",
        "    batch =  (input_tensor.unsqueeze(0)).repeat_interleave(1, dim = 0)\n",
        "    patched_batch = place_patch(batch, patch_tensor, coordinates)\n",
        "    return patched_batch[0]"
      ],
      "metadata": {
        "id": "MCZQZzvXAdKK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_5_predictions(input_image_path, resize_input_image, patch_tensor, patch_coordinates, model, label_names, plot_save_path):\n",
        "\n",
        "    input_pil_image = Image.open(input_image_path)\n",
        "    if resize_input_image:\n",
        "        input_pil_image = input_pil_image.resize((224,224), Image.CUBIC)\n",
        "    tensor_transform = T.ToTensor()\n",
        "    input_tensor = tensor_transform(input_pil_image)\n",
        "    input_tensor = torch.transpose(input_tensor, 2, 1)\n",
        "\n",
        "    input_show = np.empty_like(input_tensor.permute(2,1,0))\n",
        "    input_show[:] = input_tensor.permute(2,1,0)\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=2, ncols=2)\n",
        "    ax[0][0].imshow(input_show)\n",
        "    \n",
        "    ax[0][0].set_xlabel('Input', size=13)\n",
        "    ax[0][0].axis('on')\n",
        "\n",
        "    attacked = attack_image(input_tensor, patch_tensor, patch_coordinates)\n",
        "\n",
        "    ax[1][0].imshow(attacked.permute(2,1,0))\n",
        "    ax[1][0].set_xlabel('Adversarial Input'+\" [patch (x=\"+str(patch_coordinates[0])+\" y=\"+str(patch_coordinates[1])+\")]\", size=13)\n",
        "    ax[1][0].axis('on')\n",
        "\n",
        "    input_1 = input_tensor.unsqueeze(0).type(torch.cuda.FloatTensor).to(device)\n",
        "    input_2 = attacked.unsqueeze(0).type(torch.cuda.FloatTensor).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        results_1 = torch.softmax(model(input_1), dim=-1).cpu()[0]\n",
        "        results_2 = torch.softmax(model(input_2), dim=-1).cpu()[0]\n",
        "        values_1, indices_1 = results_1.topk(5)\n",
        "        values_2, indices_2 = results_2.topk(5)\n",
        "\n",
        "    argmax_1, argmax_2 = torch.argmax(results_1), torch.argmax(results_2)\n",
        "    names_1, names_2 = label_names[indices_1.cpu().numpy()], label_names[indices_2.cpu().numpy()]\n",
        "\n",
        "    ax[0][1].barh([i for i in range(5)], torch.flip(values_1*100, [0]), color=['navy', 'navy', 'navy','navy', 'green'])\n",
        "    ax[0][1].set_xlim([0, 100])\n",
        "    ax[0][1].set_yticks([i for i in range(5)])\n",
        "    ax[0][1].set_yticklabels(names_1[::-1], rotation=0, size=13)\n",
        "    # ax[0][1].set_ylabel('Classifier Output')\n",
        "    ax[0][1].set_xlabel('Confidence', size=13)\n",
        "    ax[0][1].grid()\n",
        "    \n",
        "    ax[1][1].barh([i for i in range(5)], torch.flip(values_2*100, [0]), color=['navy', 'navy', 'navy','navy', 'red'])\n",
        "    ax[1][1].set_xlim([0, 100])\n",
        "    ax[1][1].set_yticks([i for i in range(5)])\n",
        "    ax[1][1].set_yticklabels(names_2[::-1], rotation=0, size=13)\n",
        "    # ax[1][1].set_ylabel('Classifier Output')\n",
        "    ax[1][1].set_xlabel('Confidence', size=13)\n",
        "    ax[1][1].grid()\n",
        "\n",
        "    if plot_save_path:\n",
        "        plt.savefig(plot_save_path, bbox_inches='tight')\n"
      ],
      "metadata": {
        "id": "wRIrynqOZBAR"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (19,10)\n",
        "top_5_predictions(input_image_path = 'assault_rifle.jpg', \n",
        "                  resize_input_image = True, \n",
        "                  patch_tensor = final_patch_tensor.detach(), \n",
        "                  patch_coordinates = (184-32, 184-32), # set None for random coordinates\n",
        "                  model = model, \n",
        "                  label_names = short_labels,\n",
        "                  plot_save_path=\"foo2.png\")"
      ],
      "metadata": {
        "id": "-tBkPT3-cOZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir test11"
      ],
      "metadata": {
        "id": "OJFh6Nt9wEIS"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "n=0\n",
        "for y in range(16, 224-32, 16):\n",
        "    clear_output(wait=True)\n",
        "    for x in range(16, 224-32, 16):\n",
        "        top_5_predictions(input_image_path = 'assault_rifle.jpg', \n",
        "                  resize_input_image = True, \n",
        "                  patch_tensor = final_patch_tensor.detach(), \n",
        "                  patch_coordinates = (x, y), # set None for random coordinates\n",
        "                  model = model, \n",
        "                  label_names = short_labels,\n",
        "                  plot_save_path=\"/content/test11/\"+str(n)+\".png\"\n",
        "        )\n",
        "        n+=1"
      ],
      "metadata": {
        "id": "TWQmndK4Ub9B"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/animation9.zip /content/test11"
      ],
      "metadata": {
        "id": "J-VZOxqcwu1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7MxhDhFI5Bd0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}