{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ViT-attack.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFVKSHKU6d4R"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm.notebook import tnrange, tqdm\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.nn as nn\n",
        "\n",
        "from timm import create_model\n",
        "\n",
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
        "print(\"Using device\", device)"
      ],
      "metadata": {
        "id": "ltx8Vh9a7vDo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"vit_base_patch16_224\"\n",
        "# create a ViT model : https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n",
        "model = create_model(model_name, pretrained=True).to(device)"
      ],
      "metadata": {
        "id": "iF8Y0tPE92V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transforms for test\n",
        "IMG_SIZE = (224, 224)\n",
        "NORMALIZE_MEAN = (0.5, 0.5, 0.5)\n",
        "NORMALIZE_STD = (0.5, 0.5, 0.5)\n",
        "transforms = [\n",
        "              T.Resize(IMG_SIZE),\n",
        "              T.ToTensor(),\n",
        "              T.Normalize(NORMALIZE_MEAN, NORMALIZE_STD)\n",
        "              ]\n",
        "\n",
        "transforms = T.Compose(transforms)"
      ],
      "metadata": {
        "id": "Cx2x4B_D958j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# ImageNet Labels\n",
        "!wget https://storage.googleapis.com/bit_models/ilsvrc2012_wordnet_lemmas.txt\n",
        "imagenet_labels = dict(enumerate(open('ilsvrc2012_wordnet_lemmas.txt')))\n",
        "\n",
        "# Demo Image\n",
        "!wget https://github.com/hirotomusiker/schwert_colab_data_storage/blob/master/images/vit_demo/santorini.png?raw=true -O santorini.png\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Senior_Airman_Benton_Pohlman_fires_an_M4_carbine_rifle_%2834135723246%29.jpg/1200px-Senior_Airman_Benton_Pohlman_fires_an_M4_carbine_rifle_%2834135723246%29.jpg -O assault_rifle.jpg\n",
        "img = PIL.Image.open('santorini.png')\n",
        "img_tensor = transforms(img).unsqueeze(0).to(device)\n",
        "\n",
        "#quick test\n",
        "output = model(img_tensor)\n",
        "print(imagenet_labels[int(torch.argmax(output))])"
      ],
      "metadata": {
        "id": "w5C3Hb3U99SG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR_MEANS, TENSOR_STD = torch.FloatTensor(NORMALIZE_MEAN)[:,None,None], torch.FloatTensor(NORMALIZE_STD)[:,None,None]\n",
        "def patch_forward(patch):\n",
        "    # Map patch values from [-infty,infty] to min and max\n",
        "    patch = (torch.tanh(patch) + 1 - 2 * TENSOR_MEANS) / (2 * TENSOR_STD)\n",
        "    return patch\n",
        "\n",
        "def place_patch(img, patch):\n",
        "    for i in range(img.shape[0]):\n",
        "        temp = img[i]\n",
        "        h_offset = np.random.randint(0,img.shape[2]-patch.shape[1]-1)\n",
        "        w_offset = np.random.randint(0,img.shape[3]-patch.shape[2]-1)\n",
        "        temp[:, h_offset:h_offset+patch.shape[1],w_offset:w_offset+patch.shape[2]] = patch_forward(patch)\n",
        "        img[i] = temp\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "Xv8FOhiA99LL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patch_attack(input_image_path, resize_input_image, model, target_class, patch_size, num_epochs, pretrained_patch):\n",
        "    \n",
        "    # Create parameter and optimizer\n",
        "    patch_size = (patch_size, patch_size)\n",
        "    if pretrained_patch is None:\n",
        "        patch = nn.Parameter(torch.zeros(3, patch_size[0], patch_size[1]), requires_grad=True)\n",
        "    else:\n",
        "        patch_np = np.load(pretrained_patch)\n",
        "        patch = nn.Parameter(torch.tensor(patch_np), requires_grad=True)\n",
        "\n",
        "    optimizer = torch.optim.SGD([patch], lr=2e-1, momentum=0.8)\n",
        "    loss_module = nn.CrossEntropyLoss()\n",
        "\n",
        "    input_pil_image = Image.open(input_image_path)\n",
        "    if resize_input_image:\n",
        "        input_pil_image = input_pil_image.resize((224,224), Image.NEAREST)\n",
        "    input_tensor = tensor_transform(input_pil_image)\n",
        "    input_tensor = torch.transpose(input_tensor, 2, 1)\n",
        "\n",
        "    print(output[0][target_class])\n",
        "\n",
        "    # # Training loop\n",
        "    for epoch in tnrange(num_epochs):\n",
        "\n",
        "        batch =  (input_tensor.unsqueeze(0)).repeat_interleave(16, dim = 0)\n",
        "        patched_batch = place_patch(batch, patch)\n",
        "        pred = model(patched_batch.to(device))\n",
        "        labels = torch.zeros(patched_batch.shape[0], device=pred.device, dtype=torch.long).fill_(target_class)\n",
        "        loss = loss_module(pred, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.mean().backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    patch_temp=patch.detach().cpu().permute(2, 1, 0)\n",
        "    patch_temp = (torch.tanh(patch_temp) + 1) / 2\n",
        "    patch_temp = np.clip(patch_temp, a_min=0.0, a_max=1.0)\n",
        "    plt.imshow(patch_temp)\n",
        "    plt.grid(False)\n",
        "    plt.show()\n",
        "    print(\"op/ on target class <beta>\", pred[0][target_class])\n",
        "\n",
        "    return(patch)"
      ],
      "metadata": {
        "id": "_Bt4is95wiXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
        "final_patch_tensor = patch_attack(input_image_path='assault_rifle.jpg',\n",
        "                                  resize_input_image = True,\n",
        "                                  model = model, \n",
        "                                  target_class = 605,\n",
        "                                  patch_size = 32,\n",
        "                                  num_epochs = 200,\n",
        "                                  pretrained_patch=None)"
      ],
      "metadata": {
        "id": "QlorYE8BJf3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NormalizeData(data):\n",
        "    return (data - np.min(data)) / (np.max(data) - np.min(data))\n",
        "\n",
        "def attack_image(input_tensor, patch_tensor):\n",
        "    batch =  (input_tensor.unsqueeze(0)).repeat_interleave(1, dim = 0)\n",
        "    patched_batch = place_patch(batch, patch_tensor)\n",
        "    return patched_batch[0]"
      ],
      "metadata": {
        "id": "MCZQZzvXAdKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_5_predictions(input_image_path, resize_input_image, patch_tensor, model, label_names):\n",
        "\n",
        "    input_pil_image = Image.open(input_image_path)\n",
        "    if resize_input_image:\n",
        "        input_pil_image = input_pil_image.resize((224,224), Image.NEAREST)\n",
        "    tensor_transform = T.ToTensor()\n",
        "    input_tensor = tensor_transform(input_pil_image)\n",
        "    input_tensor = torch.transpose(input_tensor, 2, 1)\n",
        "\n",
        "    input_show = np.empty_like(input_tensor.permute(2,1,0))\n",
        "    input_show[:] = input_tensor.permute(2,1,0)\n",
        "\n",
        "    fig, ax = plt.subplots(nrows=2, ncols=2)\n",
        "    ax[0][0].imshow(input_show)\n",
        "    ax[0][0].set_xlabel('Input')\n",
        "\n",
        "    attacked = attack_image(input_tensor, patch_tensor)\n",
        "\n",
        "    ax[0][1].imshow(attacked.permute(2,1,0))\n",
        "    ax[0][1].set_xlabel('Adversarial Input')\n",
        "\n",
        "    input_1 = input_tensor.unsqueeze(0).type(torch.cuda.FloatTensor).to(device)\n",
        "    input_2 = attacked.unsqueeze(0).type(torch.cuda.FloatTensor).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        results_1 = torch.softmax(model(input_1), dim=-1).cpu()[0]\n",
        "        results_2 = torch.softmax(model(input_2), dim=-1).cpu()[0]\n",
        "        values_1, indices_1 = results_1.topk(5)\n",
        "        values_2, indices_2 = results_2.topk(5)\n",
        "\n",
        "    argmax_1, argmax_2 = torch.argmax(results_1), torch.argmax(results_2)\n",
        "    names_1, names_2 = label_names[indices_1.cpu().numpy()], label_names[indices_2.cpu().numpy()]\n",
        "\n",
        "    ax[1][0].bar([i for i in range(5)], values_1*100, color=['green', 'navy', 'navy','navy', 'navy'])\n",
        "    ax[1][0].set_ylim([0, 100])\n",
        "    ax[1][0].set_xticks([i for i in range(5)])\n",
        "    ax[1][0].set_xticklabels(names_1, rotation=90)\n",
        "    ax[1][0].set_xlabel('Classifier Output')\n",
        "    ax[1][0].set_ylabel('Confidence')\n",
        "    ax[1][0].grid()\n",
        "    \n",
        "    ax[1][1].bar([i for i in range(5)], values_2*100, color=['red', 'navy', 'navy','navy', 'navy'])\n",
        "    ax[1][1].set_ylim([0, 100])\n",
        "    ax[1][1].set_xticks([i for i in range(5)])\n",
        "    ax[1][1].set_xticklabels(names_2, rotation=90)\n",
        "    ax[1][1].set_xlabel('Classifier Output')\n",
        "    ax[1][1].set_ylabel('Confidence')\n",
        "    ax[1][1].grid()\n"
      ],
      "metadata": {
        "id": "wRIrynqOZBAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "labels_np = np.array(list(imagenet_labels.values()))\n",
        "top_5_predictions(input_image_path = 'assault_rifle.jpg', \n",
        "                  resize_input_image = True, \n",
        "                  patch_tensor = final_patch_tensor.detach(), \n",
        "                  model = model, \n",
        "                  label_names = labels_np)"
      ],
      "metadata": {
        "id": "-tBkPT3-cOZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TWQmndK4Ub9B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}